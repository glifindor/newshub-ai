name: CI/CD Pipeline for NewsHub AI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  DOCKER_HUB_USERNAME: ${{ secrets.DOCKER_HUB_USERNAME }}
  SERVER_HOST: 151.241.228.203
  SERVER_USER: root

jobs:
  # ============================================
  # Job 1: Тестирование Backend
  # ============================================
  test-backend:
    name: Test Backend
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: testdb
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          cd backend
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-asyncio pytest-cov httpx
      
      - name: Run linter
        run: |
          cd backend
          pip install flake8 black isort
          flake8 app --count --select=E9,F63,F7,F82 --show-source --statistics
          black --check app
          isort --check-only app
      
      - name: Run tests
        env:
          DATABASE_URL: postgresql+asyncpg://testuser:testpass@localhost:5432/testdb
          REDIS_URL: redis://localhost:6379/0
          JWT_SECRET_KEY: test_secret_key_for_ci
          ENVIRONMENT: testing
        run: |
          cd backend
          pytest tests/ -v --cov=app --cov-report=xml --cov-report=term
      
      - name: Upload coverage
        uses: codecov/codecov-action@v4
        with:
          file: ./backend/coverage.xml
          flags: backend
          name: backend-coverage

  # ============================================
  # Job 2: Тестирование Frontend
  # ============================================
  test-frontend:
    name: Test Frontend
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
      
      - name: Install dependencies
        run: |
          cd frontend
          npm ci
      
      - name: Run linter
        run: |
          cd frontend
          npm run lint
      
      # Type check временно отключен (нужно установить зависимости)
      # - name: Run type check
      #   run: |
      #     cd frontend
      #     npm run type-check
      
      - name: Run tests
        run: |
          cd frontend
          npm run test
      
      - name: Build
        run: |
          cd frontend
          npm run build

  # ============================================
  # Job 3: Build и Push Docker Images
  # ============================================
  build-and-push:
    name: Build and Push Docker Images
    needs: [test-backend, test-frontend]
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_HUB_USERNAME }}
          password: ${{ secrets.DOCKER_HUB_TOKEN }}
      
      - name: Extract metadata
        id: meta
        run: |
          echo "SHORT_SHA=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT
          echo "DATE=$(date +'%Y%m%d%H%M%S')" >> $GITHUB_OUTPUT
      
      # Build Backend
      - name: Build and push Backend
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          file: ./backend/Dockerfile.prod
          push: true
          provenance: false
          tags: |
            ${{ secrets.DOCKER_HUB_USERNAME }}/newshub-backend:latest
            ${{ secrets.DOCKER_HUB_USERNAME }}/newshub-backend:${{ steps.meta.outputs.SHORT_SHA }}
          cache-from: type=registry,ref=${{ secrets.DOCKER_HUB_USERNAME }}/newshub-backend:buildcache
          cache-to: type=registry,ref=${{ secrets.DOCKER_HUB_USERNAME }}/newshub-backend:buildcache,mode=max
      
      # Build Frontend
      - name: Build and push Frontend
        uses: docker/build-push-action@v5
        with:
          context: ./frontend
          file: ./frontend/Dockerfile.prod
          push: true
          provenance: false
          build-args: |
            NEXT_PUBLIC_API_URL=http://151.241.228.203/api
            NEXT_PUBLIC_WS_URL=ws://151.241.228.203
          tags: |
            ${{ secrets.DOCKER_HUB_USERNAME }}/newshub-frontend:latest
            ${{ secrets.DOCKER_HUB_USERNAME }}/newshub-frontend:${{ steps.meta.outputs.SHORT_SHA }}
          cache-from: type=registry,ref=${{ secrets.DOCKER_HUB_USERNAME }}/newshub-frontend:buildcache
          cache-to: type=registry,ref=${{ secrets.DOCKER_HUB_USERNAME }}/newshub-frontend:buildcache,mode=max
      
      # Build Nginx
      - name: Build and push Nginx
        uses: docker/build-push-action@v5
        with:
          context: ./nginx
          file: ./nginx/Dockerfile
          push: true
          provenance: false
          tags: |
            ${{ secrets.DOCKER_HUB_USERNAME }}/newshub-nginx:latest
            ${{ secrets.DOCKER_HUB_USERNAME }}/newshub-nginx:${{ steps.meta.outputs.SHORT_SHA }}

  # ============================================
  # Job 4: Deploy to Production Server
  # ============================================
  deploy:
    name: Deploy to Production
    needs: [build-and-push]
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H ${{ env.SERVER_HOST }} >> ~/.ssh/known_hosts
      
      - name: Create .env file
        run: |
          cat > .env.prod << EOF
          DOCKER_HUB_USERNAME=${{ secrets.DOCKER_HUB_USERNAME }}
          # Database
          POSTGRES_USER=${{ secrets.POSTGRES_USER }}
          POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_DB=${{ secrets.POSTGRES_DB }}
          
          # Redis
          REDIS_PASSWORD=${{ secrets.REDIS_PASSWORD }}
          
          # RabbitMQ
          RABBITMQ_USER=${{ secrets.RABBITMQ_USER }}
          RABBITMQ_PASS=${{ secrets.RABBITMQ_PASS }}
          
          # JWT
          JWT_SECRET_KEY=${{ secrets.JWT_SECRET_KEY }}
          
          # APIs
          OPENROUTER_API_KEY=${{ secrets.OPENROUTER_API_KEY }}
          FREEPIK_API_KEY=${{ secrets.FREEPIK_API_KEY }}
          NEWSAPI_KEY=${{ secrets.NEWSAPI_KEY }}
          
          # Telegram
          TELEGRAM_BOT_TOKEN=${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CRYPTO_CHANNEL=${{ secrets.TELEGRAM_CRYPTO_CHANNEL }}
          TELEGRAM_POLITICS_CHANNEL=${{ secrets.TELEGRAM_POLITICS_CHANNEL }}
          TELEGRAM_ADMIN_CHAT_ID=${{ secrets.TELEGRAM_ADMIN_CHAT_ID }}
          
          # Monitoring
          GRAFANA_USER=${{ secrets.GRAFANA_USER }}
          GRAFANA_PASSWORD=${{ secrets.GRAFANA_PASSWORD }}
          FLOWER_USER=${{ secrets.FLOWER_USER }}
          FLOWER_PASSWORD=${{ secrets.FLOWER_PASSWORD }}
          
          # Frontend
          NEXT_PUBLIC_API_URL=http://151.241.228.203/api
          NEXT_PUBLIC_WS_URL=ws://151.241.228.203
          
          # Environment
          ENVIRONMENT=production
          EOF
          
          # Verify .env.prod was created successfully
          if [ ! -f .env.prod ]; then
            echo "❌ ERROR: .env.prod file was not created!"
            exit 1
          fi
          
          echo "✅ .env.prod created successfully"
          echo "File size: $(wc -c < .env.prod) bytes"
          echo "Number of lines: $(wc -l < .env.prod)"
          
          # Show file structure (without sensitive values)
          echo "Environment variables structure:"
          grep -E "^[A-Z_]+=.+" .env.prod | sed 's/=.*/=***/' | head -20
          
          # Check for empty critical variables
          echo ""
          echo "Checking critical variables:"
          if grep -q "^POSTGRES_PASSWORD=$" .env.prod; then
            echo "❌ WARNING: POSTGRES_PASSWORD is EMPTY!"
          else
            echo "✅ POSTGRES_PASSWORD is set"
          fi
          
          if grep -q "^POSTGRES_USER=$" .env.prod; then
            echo "❌ WARNING: POSTGRES_USER is EMPTY!"
          else
            echo "✅ POSTGRES_USER is set"
          fi
      
      - name: Copy files to server
        run: |
          # Ensure target directory exists
          ssh -i ~/.ssh/id_rsa ${{ env.SERVER_USER }}@${{ env.SERVER_HOST }} "mkdir -p /opt/newshub"
          
          # Copy files
          scp -i ~/.ssh/id_rsa .env.prod ${{ env.SERVER_USER }}@${{ env.SERVER_HOST }}:/opt/newshub/.env
          scp -i ~/.ssh/id_rsa docker-compose.prod.yml ${{ env.SERVER_USER }}@${{ env.SERVER_HOST }}:/opt/newshub/docker-compose.yml
          scp -r -i ~/.ssh/id_rsa nginx ${{ env.SERVER_USER }}@${{ env.SERVER_HOST }}:/opt/newshub/
          scp -r -i ~/.ssh/id_rsa monitoring ${{ env.SERVER_USER }}@${{ env.SERVER_HOST }}:/opt/newshub/
          
          # Verify .env file was copied and is not empty
          ssh -i ~/.ssh/id_rsa ${{ env.SERVER_USER }}@${{ env.SERVER_HOST }} << 'VERIFY'
            if [ ! -f /opt/newshub/.env ]; then
              echo "❌ ERROR: .env file not found on server!"
              exit 1
            fi
            
            ENV_SIZE=$(wc -c < /opt/newshub/.env)
            if [ "$ENV_SIZE" -eq 0 ]; then
              echo "❌ ERROR: .env file is empty on server!"
              exit 1
            fi
            
            echo "✅ .env file copied successfully to server"
            echo "File size: $ENV_SIZE bytes"
            echo "Number of lines: $(wc -l < /opt/newshub/.env)"
          VERIFY
      
      - name: Deploy on server
        run: |
          ssh -i ~/.ssh/id_rsa ${{ env.SERVER_USER }}@${{ env.SERVER_HOST }} << 'ENDSSH'
            cd /opt/newshub
            
            # Final verification that .env exists and is not empty
            if [ ! -f .env ] || [ ! -s .env ]; then
              echo "❌ FATAL ERROR: .env file is missing or empty in /opt/newshub/"
              ls -la /opt/newshub/ || true
              exit 1
            fi
            
            echo "✅ .env file verified in /opt/newshub/"
            echo "File size: $(wc -c < .env) bytes"
            
            mkdir -p /opt/newshub/backups
            
            # Load environment variables for shell commands
            set -a
            source .env
            set +a

            # Ensure modern docker-compose binary available (workaround for ContainerConfig bug)
            if ! docker-compose version 2>/dev/null | grep -q "v2"; then
              curl -sSL "https://github.com/docker/compose/releases/download/v2.24.7/docker-compose-linux-x86_64" -o /usr/local/bin/docker-compose
              chmod +x /usr/local/bin/docker-compose
            fi
            
            # Pull latest images
            docker-compose --env-file .env pull
            
            # Backup database before update (skip if no DB exists yet)
            if docker-compose --env-file .env ps postgres 2>/dev/null | grep -q "Up"; then
              echo "Creating database backup..."
              timeout 30 docker-compose --env-file .env exec -T postgres pg_dump -U ${POSTGRES_USER} ${POSTGRES_DB} > /opt/newshub/backups/backup_$(date +%Y%m%d_%H%M%S).sql 2>&1 || {
                echo "⚠️  Backup failed or timed out (exit code: $?), continuing deployment..."
              }
            else
              echo "PostgreSQL not running yet, skipping backup..."
            fi
            
            # Stop and remove old containers to avoid metadata issues
            docker-compose --env-file .env down --remove-orphans
            docker-compose --env-file .env rm -f -s -v backend frontend nginx postgres redis rabbitmq celery_worker celery_beat celery_flower || true

            # Start core services back up
            docker-compose --env-file .env up -d postgres redis rabbitmq
            
            # Wait for containers to start (not checking health yet)
            echo "Waiting for containers to start..."
            sleep 15
            
            # Show logs for debugging if services are unhealthy
            echo "Checking service status..."
            docker-compose --env-file .env ps
            
            # Always show PostgreSQL logs to debug startup issues
            echo "=== PostgreSQL logs (last 50 lines) ==="
            docker-compose --env-file .env logs --tail=50 postgres
            
            # Always show RabbitMQ logs to debug startup issues
            echo "=== RabbitMQ logs (last 50 lines) ==="
            docker-compose --env-file .env logs --tail=50 rabbitmq
            
            # Show Redis logs for comparison (it works)
            echo "=== Redis logs (last 20 lines) ==="
            docker-compose --env-file .env logs --tail=20 redis
            
            # Load environment variables for readiness checks
            set -a
            source .env
            set +a
            
            # Active readiness checks for each service with longer timeouts
            echo "Performing active readiness checks..."
            
            # Check PostgreSQL (extended to 60 attempts = 2 minutes)
            POSTGRES_READY=false
            for i in {1..60}; do
              if docker-compose --env-file .env exec -T postgres pg_isready -U ${POSTGRES_USER} >/dev/null 2>&1; then
                echo "✅ PostgreSQL is ready"
                POSTGRES_READY=true
                break
              else
                echo "⏳ Waiting for PostgreSQL... ($i/60)"
                sleep 2
              fi
            done
            
            if [ "$POSTGRES_READY" = false ]; then
              echo "❌ PostgreSQL failed to become ready. Dumping logs:"
              docker-compose --env-file .env logs --tail=50 postgres
              exit 1
            fi
            
            # Check Redis (extended to 40 attempts)
            REDIS_READY=false
            for i in {1..40}; do
              if docker-compose --env-file .env exec -T redis redis-cli --no-auth-warning -a ${REDIS_PASSWORD} ping >/dev/null 2>&1; then
                echo "✅ Redis is ready"
                REDIS_READY=true
                break
              else
                echo "⏳ Waiting for Redis... ($i/40)"
                sleep 2
              fi
            done
            
            if [ "$REDIS_READY" = false ]; then
              echo "❌ Redis failed to become ready. Dumping logs:"
              docker-compose --env-file .env logs --tail=50 redis
              exit 1
            fi
            
            # Check RabbitMQ (extended to 40 attempts)
            RABBITMQ_READY=false
            for i in {1..40}; do
              if docker-compose --env-file .env exec -T rabbitmq rabbitmq-diagnostics check_running >/dev/null 2>&1; then
                echo "✅ RabbitMQ is ready"
                RABBITMQ_READY=true
                break
              else
                echo "⏳ Waiting for RabbitMQ... ($i/40)"
                sleep 2
              fi
            done
            
            if [ "$RABBITMQ_READY" = false ]; then
              echo "❌ RabbitMQ failed to become ready. Dumping logs:"
              docker-compose --env-file .env logs --tail=50 rabbitmq
              exit 1
            fi
            
            echo "✅ All infrastructure services are fully ready!"

            # Recreate backend first and wait for it to become ready
            docker-compose --env-file .env up -d backend
            sleep 60

            # Run migrations inside backend container
            docker-compose --env-file .env exec -T backend /opt/venv/bin/alembic upgrade head

            # Recreate frontend and nginx once backend is healthy
            docker-compose --env-file .env up -d --force-recreate frontend nginx

            # Ensure worker services are running with the new image
            docker-compose --env-file .env up -d celery_worker celery_beat celery_flower
            
            # Clean up old images
            docker image prune -af --filter "until=72h"
            
            echo "Deployment completed successfully!"
          ENDSSH
      
      - name: Health check
        run: |
          sleep 10
          response=$(curl -s -o /dev/null -w "%{http_code}" http://${{ env.SERVER_HOST }}/health)
          if [ $response -eq 200 ]; then
            echo "✅ Health check passed"
          else
            echo "❌ Health check failed with status $response"
            exit 1
          fi
      
      - name: Send notification to Telegram
        if: always()
        run: |
          if [ "${{ job.status }}" == "success" ]; then
            MESSAGE="✅ Deployment SUCCESS%0A%0ACommit: ${{ github.sha }}%0AAuthor: ${{ github.actor }}%0ATime: $(date)"
          else
            MESSAGE="❌ Deployment FAILED%0A%0ACommit: ${{ github.sha }}%0AAuthor: ${{ github.actor }}%0ATime: $(date)"
          fi
          
          curl -X POST "https://api.telegram.org/bot${{ secrets.TELEGRAM_BOT_TOKEN }}/sendMessage" \
            -d "chat_id=${{ secrets.TELEGRAM_ADMIN_CHAT_ID }}" \
            -d "text=$MESSAGE"

  # ============================================
  # Job 5: Smoke Tests Post-Deploy
  # ============================================
  smoke-tests:
    name: Smoke Tests
    needs: [deploy]
    runs-on: ubuntu-latest
    
    steps:
      - name: Test API Health
        run: |
          response=$(curl -s http://${{ env.SERVER_HOST }}/health)
          echo "Response: $response"
          
          status=$(echo $response | jq -r '.status')
          if [ "$status" != "healthy" ]; then
            echo "❌ API health check failed"
            exit 1
          fi
          echo "✅ API is healthy"
      
      - name: Test Frontend
        run: |
          response=$(curl -s -o /dev/null -w "%{http_code}" http://${{ env.SERVER_HOST }})
          if [ $response -ne 200 ]; then
            echo "❌ Frontend is not responding"
            exit 1
          fi
          echo "✅ Frontend is accessible"
      
      - name: Test API Documentation
        run: |
          response=$(curl -s -o /dev/null -w "%{http_code}" http://${{ env.SERVER_HOST }}/docs)
          if [ $response -ne 200 ]; then
            echo "❌ API docs not accessible"
            exit 1
          fi
          echo "✅ API docs are accessible"
      
      - name: Test Database Connection
        run: |
          response=$(curl -s http://${{ env.SERVER_HOST }}/health)
          db_status=$(echo $response | jq -r '.database')
          if [ "$db_status" != "connected" ]; then
            echo "❌ Database connection failed"
            exit 1
          fi
          echo "✅ Database is connected"
