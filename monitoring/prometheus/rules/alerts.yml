groups:
  - name: newshub_alerts
    interval: 30s
    rules:
      # ============================================
      # API Health Alerts
      # ============================================
      - alert: APIDown
        expr: up{job="backend"} == 0
        for: 2m
        labels:
          severity: critical
          component: backend
        annotations:
          summary: "Backend API is DOWN"
          description: "Backend API has been down for more than 2 minutes"

      - alert: APIHighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="backend"}[5m])) > 2
        for: 5m
        labels:
          severity: warning
          component: backend
        annotations:
          summary: "High API latency detected"
          description: "95th percentile latency is above 2 seconds"

      - alert: APIHighErrorRate
        expr: rate(http_requests_total{job="backend",status=~"5.."}[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
          component: backend
        annotations:
          summary: "High API error rate"
          description: "More than 5% of requests are failing (5xx errors)"

      # ============================================
      # Database Alerts
      # ============================================
      - alert: PostgreSQLDown
        expr: up{job="postgres"} == 0
        for: 1m
        labels:
          severity: critical
          component: database
        annotations:
          summary: "PostgreSQL is DOWN"
          description: "PostgreSQL database has been down for more than 1 minute"

      - alert: PostgreSQLTooManyConnections
        expr: sum(pg_stat_activity_count) > 80
        for: 5m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "Too many PostgreSQL connections"
          description: "More than 80 active connections to PostgreSQL"

      - alert: PostgreSQLSlowQueries
        expr: rate(pg_stat_statements_mean_exec_time[5m]) > 1000
        for: 10m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "Slow PostgreSQL queries detected"
          description: "Average query execution time is above 1 second"

      # ============================================
      # Redis Alerts
      # ============================================
      - alert: RedisDown
        expr: up{job="redis"} == 0
        for: 1m
        labels:
          severity: critical
          component: cache
        annotations:
          summary: "Redis is DOWN"
          description: "Redis cache has been down for more than 1 minute"

      - alert: RedisHighMemoryUsage
        expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.9
        for: 5m
        labels:
          severity: warning
          component: cache
        annotations:
          summary: "Redis memory usage is high"
          description: "Redis is using more than 90% of available memory"

      # ============================================
      # RabbitMQ Alerts
      # ============================================
      - alert: RabbitMQDown
        expr: up{job="rabbitmq"} == 0
        for: 2m
        labels:
          severity: critical
          component: queue
        annotations:
          summary: "RabbitMQ is DOWN"
          description: "RabbitMQ message broker has been down for more than 2 minutes"

      - alert: RabbitMQTooManyMessages
        expr: rabbitmq_queue_messages > 10000
        for: 10m
        labels:
          severity: warning
          component: queue
        annotations:
          summary: "Too many messages in RabbitMQ queue"
          description: "Queue has more than 10,000 pending messages"

      # ============================================
      # System Alerts
      # ============================================
      - alert: HighCPUUsage
        expr: 100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 10m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is above 80% for more than 10 minutes"

      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 5m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is above 85%"

      - alert: DiskSpaceLow
        expr: (node_filesystem_avail_bytes{fstype!~"tmpfs|fuse.*"} / node_filesystem_size_bytes{fstype!~"tmpfs|fuse.*"}) * 100 < 15
        for: 5m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "Low disk space"
          description: "Less than 15% disk space available"

      - alert: DiskSpaceCritical
        expr: (node_filesystem_avail_bytes{fstype!~"tmpfs|fuse.*"} / node_filesystem_size_bytes{fstype!~"tmpfs|fuse.*"}) * 100 < 5
        for: 1m
        labels:
          severity: critical
          component: system
        annotations:
          summary: "Critical disk space"
          description: "Less than 5% disk space available - CRITICAL!"

      # ============================================
      # Container Alerts
      # ============================================
      - alert: ContainerDown
        expr: up == 0
        for: 2m
        labels:
          severity: warning
          component: container
        annotations:
          summary: "Container is down"
          description: "Container {{ $labels.instance }} has been down for more than 2 minutes"

      - alert: ContainerHighCPU
        expr: rate(container_cpu_usage_seconds_total[5m]) > 0.8
        for: 5m
        labels:
          severity: warning
          component: container
        annotations:
          summary: "Container high CPU usage"
          description: "Container {{ $labels.name }} is using more than 80% CPU"

      - alert: ContainerHighMemory
        expr: container_memory_usage_bytes / container_spec_memory_limit_bytes > 0.9
        for: 5m
        labels:
          severity: warning
          component: container
        annotations:
          summary: "Container high memory usage"
          description: "Container {{ $labels.name }} is using more than 90% of memory limit"

      # ============================================
      # Celery Alerts
      # ============================================
      - alert: CeleryWorkerDown
        expr: celery_worker_up == 0
        for: 2m
        labels:
          severity: critical
          component: worker
        annotations:
          summary: "Celery worker is down"
          description: "Celery worker has been down for more than 2 minutes"

      - alert: CeleryHighTaskQueue
        expr: celery_queue_length > 1000
        for: 10m
        labels:
          severity: warning
          component: worker
        annotations:
          summary: "High Celery task queue"
          description: "More than 1000 tasks waiting in Celery queue"

      - alert: CeleryTaskFailureRate
        expr: rate(celery_task_failed_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
          component: worker
        annotations:
          summary: "High Celery task failure rate"
          description: "More than 10% of Celery tasks are failing"

      # ============================================
      # Application Alerts
      # ============================================
      - alert: NewsCollectionFailed
        expr: increase(news_collection_errors_total[1h]) > 10
        for: 5m
        labels:
          severity: warning
          component: pipeline
        annotations:
          summary: "News collection failures"
          description: "More than 10 news collection errors in the last hour"

      - alert: TelegramPostingFailed
        expr: increase(telegram_post_errors_total[1h]) > 5
        for: 5m
        labels:
          severity: warning
          component: telegram
        annotations:
          summary: "Telegram posting failures"
          description: "More than 5 Telegram posting errors in the last hour"

      - alert: OpenRouterAPIErrors
        expr: increase(openrouter_api_errors_total[1h]) > 20
        for: 5m
        labels:
          severity: warning
          component: ai
        annotations:
          summary: "OpenRouter API errors"
          description: "More than 20 OpenRouter API errors in the last hour"
